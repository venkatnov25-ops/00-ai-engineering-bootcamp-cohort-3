{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b329097",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ce1f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Prefetch, Filter, FieldCondition, MatchText, FusionQuery, Document\n",
    "\n",
    "\n",
    "from langsmith import traceable, get_current_run_tree\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.types import Send, Command\n",
    "\n",
    "from langchain_core.messages import AIMessage, ToolMessage, convert_to_openai_messages\n",
    "\n",
    "from jinja2 import Template\n",
    "from typing import Literal, Dict, Any, Annotated, List, Optional, Sequence\n",
    "from IPython.display import Image, display\n",
    "from operator import add\n",
    "from openai import OpenAI\n",
    "\n",
    "import openai\n",
    "\n",
    "import random\n",
    "import ast\n",
    "import inspect\n",
    "import instructor\n",
    "import json\n",
    "\n",
    "from utils.utils import get_tool_descriptions, format_ai_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3396c312",
   "metadata": {},
   "source": [
    "### Define Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76d0e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"embed_query\",\n",
    "    run_type=\"embedding\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"text-embedding-3-small\"}\n",
    ")\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    response = openai.embeddings.create(\n",
    "        input=text,\n",
    "        model=model,\n",
    "    )\n",
    "\n",
    "    current_run = get_current_run_tree()\n",
    "\n",
    "    if current_run:\n",
    "        current_run.metadata[\"usage_metadata\"] = {\n",
    "            \"input_tokens\": response.usage.prompt_tokens,\n",
    "            \"total_tokens\": response.usage.total_tokens,\n",
    "        }\n",
    "\n",
    "    return response.data[0].embedding\n",
    "\n",
    "\n",
    "@traceable(\n",
    "    name=\"retrieve_data\",\n",
    "    run_type=\"retriever\"\n",
    ")\n",
    "def retrieve_data(query, k=5):\n",
    "\n",
    "    query_embedding = get_embedding(query)\n",
    "\n",
    "    qdrant_client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "    results = qdrant_client.query_points(\n",
    "        collection_name=\"Amazon-items-collection-01-hybrid-search\",\n",
    "        prefetch=[\n",
    "            Prefetch(\n",
    "                query=query_embedding,\n",
    "                using=\"text-embedding-3-small\",\n",
    "                limit=20\n",
    "            ),\n",
    "            Prefetch(\n",
    "                query=Document(\n",
    "                    text=query,\n",
    "                    model=\"qdrant/bm25\"\n",
    "                ),\n",
    "                using=\"bm25\",\n",
    "                limit=20\n",
    "            )\n",
    "        ],\n",
    "        query=FusionQuery(fusion=\"rrf\"),\n",
    "        limit=k,\n",
    "    )\n",
    "\n",
    "    retrieved_context_ids = []\n",
    "    retrieved_context = []\n",
    "    similarity_scores = []\n",
    "    retrieved_context_ratings = []\n",
    "\n",
    "    for result in results.points:\n",
    "        retrieved_context_ids.append(result.payload[\"parent_asin\"])\n",
    "        retrieved_context.append(result.payload[\"description\"])\n",
    "        retrieved_context_ratings.append(result.payload[\"average_rating\"])\n",
    "        similarity_scores.append(result.score)\n",
    "\n",
    "    return {\n",
    "        \"retrieved_context_ids\": retrieved_context_ids,\n",
    "        \"retrieved_context\": retrieved_context,\n",
    "        \"retrieved_context_ratings\": retrieved_context_ratings,\n",
    "        \"similarity_scores\": similarity_scores,\n",
    "    }\n",
    "\n",
    "\n",
    "@traceable(\n",
    "    name=\"format_retrieved_context\",\n",
    "    run_type=\"prompt\"\n",
    ")\n",
    "def process_context(context):\n",
    "\n",
    "    formatted_context = \"\"\n",
    "\n",
    "    for id, chunk, rating in zip(context[\"retrieved_context_ids\"], context[\"retrieved_context\"], context[\"retrieved_context_ratings\"]):\n",
    "        formatted_context += f\"- ID: {id}, rating: {rating}, description: {chunk}\\n\"\n",
    "\n",
    "    return formatted_context\n",
    "\n",
    "\n",
    "def get_formatted_context(query: str, top_k: int = 5) -> str:\n",
    "\n",
    "    \"\"\"Get the top k context, each representing an inventory item for a given query.\n",
    "    \n",
    "    Args:\n",
    "        query: The query to get the top k context for\n",
    "        top_k: The number of context chunks to retrieve, works best with 5 or more\n",
    "    \n",
    "    Returns:\n",
    "        A string of the top k context chunks with IDs and average ratings prepending each chunk, each representing an inventory item for a given query.\n",
    "    \"\"\"\n",
    "\n",
    "    context = retrieve_data(query, top_k)\n",
    "    formatted_context = process_context(context)\n",
    "\n",
    "    return formatted_context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b16acd",
   "metadata": {},
   "source": [
    "### State and Pydantic Models for Structured Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543ba110",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tool definition\n",
    "class ToolCall(BaseModel):\n",
    "    name: str\n",
    "    arguments: dict\n",
    "\n",
    "class RAGUsedContext(BaseModel):\n",
    "    id: str = Field(description=\"The ID of the item used to answer the question\")\n",
    "    description: str = Field(description=\"Short description of the item used to answer the question\")\n",
    "    \n",
    "class AgentResponse(BaseModel):\n",
    "    answer: str = Field(description=\"Answer to the question.\")\n",
    "    references: list[RAGUsedContext] = Field(description=\"List of items used to answer the question.\")\n",
    "    final_answer: bool = False\n",
    "    tool_calls: List[ToolCall] = []\n",
    "\n",
    "## The state that is muteed foe every agent call, Reasoning and answering\n",
    "class State(BaseModel):\n",
    "    ## Iteration of messages -- all messages in the conversation\n",
    "    messages: Annotated[List[Any], add] = []\n",
    "    ## Relevancy of the question with intent router node\n",
    "    question_relevant: bool = False\n",
    "    ## Number of iterations from Agent\n",
    "    iteration: int = 0\n",
    "    ## The answer of the agent\n",
    "    answer: str = \"\"\n",
    "    ## List of available tools\n",
    "    available_tools: List[Dict[str, Any]] = []\n",
    "    ## List of tool calls -- What agent has called\n",
    "    tool_calls: List[ToolCall] = []\n",
    "    ## If Agent thinks that the final answer can be compiled\n",
    "    final_answer: bool = False\n",
    "    ## Which items were already used to answer the initial question?\n",
    "    references: Annotated[List[RAGUsedContext], add] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eededcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"agent_node\",\n",
    "    run_type=\"llm\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4.1-mini\"}\n",
    ")\n",
    "def agent_node(state: State) -> dict:\n",
    "\n",
    "   prompt_template =  \"\"\"You are a shopping assistant that can answer questions about the products in stock.\n",
    "\n",
    "You will be given a conversation history and a list of tools you can use to answer the latest query.\n",
    "\n",
    "<Available tools>\n",
    "{{ available_tools | tojson }}\n",
    "</Available tools>\n",
    "\n",
    "When making tool calls, use this exact format:\n",
    "{\n",
    "    \"name\": \"tool_name\",\n",
    "    \"arguments\": {\n",
    "        \"parameter1\": \"value1\",\n",
    "        \"parameter2\": \"value2\",\n",
    "    }\n",
    "}\n",
    "\n",
    "CRITICAL: All parameters must go inside the \"arguments\" object, not at the top level of the tool call.\n",
    "\n",
    "Examples:\n",
    "- Get formatted item context:\n",
    "{\n",
    "    \"name\": \"get_formatted_item_context\",\n",
    "    \"arguments\": {\n",
    "        \"query\": \"Kool kids toys.\",\n",
    "        \"top_k\": 5\n",
    "    }\n",
    "}\n",
    "\n",
    "CRITICAL RULES:\n",
    "- If tool_calls has values, final_answer MUST be false\n",
    "(You cannot call tools and exit the graph in the same response)\n",
    "- If final_answer is true, tool_calls MUST be []\n",
    "(You must wait for tool results before exiting the graph)\n",
    "- If you need tool results before answering, set:\n",
    "tool_calls=[...], final_answer=false\n",
    "- After receiving tool results, you can then set:\n",
    "tool_calls=[], final_answer=true\n",
    "- Use names specificly provided in the available tools. Don't add any additional text to the names.\n",
    "\n",
    "Instructions:\n",
    "- You need to answer the question based on the outputs from the tools using the available tools only.\n",
    "- Do not suggest the same tool call more than once.\n",
    "- If the question can be decomposed into multiple sub-questions, suggest all of them.\n",
    "- If multiple tool calls can be used at once to answer the question, suggest all of them.\n",
    "- Do not explain your next steps in the answer, instead use tools to answer the question.\n",
    "- Never use word context and refer to it as the available products.\n",
    "- You should only answer questions about the products in stock. If the question is not about the products in stock, you should ask for clarification.\n",
    "- As an output you need to return the following:\n",
    "\n",
    "* answer: The answer to the question based on your current knowledge and the tool results.\n",
    "* references: The list of the indexes from the chunks returned from all tool calls that were used to answer the question. If more than one chunk was used to compile the answer from a single tool call, be sure to return all of them.\n",
    "* Each reference should have an id and a short description of the item based on the retrieved context.\n",
    "* final_answer: True if you have all the information needed to provide a complete answer, False otherwise.\n",
    "\n",
    "- The answer to the question should contain detailed information about the product and should be returned with detailed specification in bullet points.\n",
    "- The short description should have the name of the item.\n",
    "- If the user's request requires using a tool, set tool_calls with the appropriate function names and arguments.\n",
    "\"\"\"\n",
    "\n",
    "   template = Template(prompt_template)\n",
    "   \n",
    "   prompt = template.render(\n",
    "      available_tools=state.available_tools\n",
    "   )\n",
    "\n",
    "   messages = state.messages\n",
    "\n",
    "   conversation = []\n",
    "\n",
    "   for message in messages:\n",
    "        conversation.append(convert_to_openai_messages(message))\n",
    "\n",
    "   client = instructor.from_openai(OpenAI())\n",
    "\n",
    "   response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        response_model=AgentResponse,\n",
    "        ## *conversation means arbitrary number of conversations\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}, *conversation],\n",
    "        temperature=0.5,\n",
    "   )\n",
    "\n",
    "   ai_message = format_ai_message(response)\n",
    "\n",
    "   return {\n",
    "      \"messages\": [ai_message],\n",
    "      \"tool_calls\": response.tool_calls,\n",
    "      \"iteration\": state.iteration + 1,\n",
    "      \"answer\": response.answer,\n",
    "      \"final_answer\": response.final_answer,\n",
    "      \"references\": response.references\n",
    "   }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2199b708",
   "metadata": {},
   "source": [
    "### Tool Router Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e44c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_router(state: State) -> str:\n",
    "    \"\"\"Decide whether to continue or end\"\"\"\n",
    "    \n",
    "    if state.final_answer:\n",
    "        return \"end\"\n",
    "    elif state.iteration > 2:\n",
    "        return \"end\"\n",
    "    elif len(state.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e0485a",
   "metadata": {},
   "source": [
    "### Intent Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751d0f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentRouterResponse(BaseModel):\n",
    "    question_relevant: bool\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457ab9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"intent_router_node\",\n",
    "    run_type=\"llm\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4.1-mini\"}\n",
    ")\n",
    "def intent_router_node(state: State):\n",
    "\n",
    "   prompt_template =  \"\"\"You are part of a shopping assistant that can answer questions about products in stock.\n",
    "\n",
    "Instructions:\n",
    "- You will be given a question and you need to clasify it into relevant or not relevant.\n",
    "- If the question is not relevant, return False in field \"question_relevant\" and set \"answer\" to explanation why it is not relevant.\n",
    "- If the question is relevant, return True in field \"question_relevant\" and set \"answer\" to \"\".\n",
    "- You should only answer questions about the products in stock. If the question is not about the products in stock, you should ask for clarification.\n",
    "\"\"\"\n",
    "\n",
    "   template = Template(prompt_template)\n",
    "   \n",
    "   prompt = template.render()\n",
    "\n",
    "   messages = state.messages\n",
    "\n",
    "   conversation = []\n",
    "\n",
    "   for message in messages:\n",
    "        conversation.append(convert_to_openai_messages(message))\n",
    "\n",
    "   client = instructor.from_openai(OpenAI())\n",
    "\n",
    "   response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        response_model=IntentRouterResponse,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}, *conversation],\n",
    "        temperature=0.5,\n",
    "   )\n",
    "\n",
    "   return {\n",
    "      \"question_relevant\": response.question_relevant,\n",
    "      \"answer\": response.answer\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb189d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intent_router_conditional_edges(state: State):\n",
    "\n",
    "    if state.question_relevant:\n",
    "        return \"agent_node\"\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796c8459",
   "metadata": {},
   "source": [
    "### Graph construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff3a9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "\n",
    "tools = [get_formatted_context]\n",
    "tool_node = ToolNode(tools)\n",
    "tool_descriptions = get_tool_descriptions(tools)\n",
    "\n",
    "workflow.add_node(\"agent_node\", agent_node)\n",
    "workflow.add_node(\"tool_node\", tool_node)\n",
    "workflow.add_node(\"intent_router_node\", intent_router_node)\n",
    "\n",
    "workflow.add_edge(START, \"intent_router_node\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"intent_router_node\",\n",
    "    intent_router_conditional_edges,\n",
    "    {\n",
    "        \"agent_node\": \"agent_node\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent_node\",\n",
    "    tool_router,\n",
    "    {\n",
    "        \"tools\": \"tool_node\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"tool_node\", \"agent_node\")\n",
    "\n",
    "graph = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429b5d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723acb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Can I get earphones for myself, a laptop bag for my wife and something cool for my kids?\"}],\n",
    "    \"available_tools\": tool_descriptions\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edab7613",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d2c117",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note in result, query decomposition to 3 messages happened by itself (Messages has 3 Tool Message)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7caf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resutl is the state object\n",
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f808731e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
