{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ecebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import json\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Filter, FieldCondition, MatchValue\n",
    "\n",
    "from langsmith import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187469a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client = QdrantClient(url=\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77cb937",
   "metadata": {},
   "source": [
    "Download all 50 items from Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d47ff32",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_points = qdrant_client.scroll(\n",
    "    collection_name=\"Amazon-items-collection-00\",\n",
    "    limit=100,\n",
    "    offset=None,\n",
    "    with_payload=True,\n",
    "    with_vectors=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc643ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_points[0][0].payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542fc38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a6433e",
   "metadata": {},
   "source": [
    "Let's get the needed fields (description for sure) for the Evals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f11c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_context = [{\"id\": data.payload[\"parent_asin\"], \"text\": data.payload[\"description\"]} for data in all_points[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc16989",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af834eec",
   "metadata": {},
   "source": [
    "Render a prompt to generate synthetic Eval reference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecded2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_schema = {\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Suggested question.\",\n",
    "            },\n",
    "            \"chunk_ids\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"ID of the chunk that could be used to answer the question.\",\n",
    "                },\n",
    "            },\n",
    "            \"answer_example\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Suggested answer grounded in the context.\",\n",
    "            },\n",
    "            \"reasoning\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Reasoning why the question could be answered with the chunks.\",\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "SYSTEM_PROMPT = f\"\"\"\n",
    "I am building a RAG application. I have a collection of 50 chunks of text.\n",
    "The RAG application will act as a shopping assistant that can answer questions about the stock of the products we have available.\n",
    "I will provide all of the available products to you with IDs of each chunk.\n",
    "I want you to come up with 30 questions to which the answers could be grounded in the chunk context.\n",
    "The questions should imitate a potential real user of this RAG system.\n",
    "As an output I need you to provide me the list of questions and the IDs of the chunks that could be used to answer them.\n",
    "Also, provide an example answer to the question given the context of the chunks.\n",
    "Also, provide the reason why you chose the chunks to answer the questions.\n",
    "Construct 10 questions that could use multiple chunks in the answer.\n",
    "Construct 15 questions that could use single chunk in the answer.\n",
    "Construct 5 questions that can't be answered with the available chunks.\n",
    "\n",
    "<OUTPUT JSON SCHEMA>\n",
    "{json.dumps(output_schema, indent=2)}\n",
    "</OUTPUT JSON SCHEMA>\n",
    "\n",
    "I need to be able to parse the json output.\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT = f\"\"\"\n",
    "Here is the list of chunks, each list element is a dictionary with id and text:\n",
    "{all_context}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e226fb96",
   "metadata": {},
   "source": [
    "A system prompt sets the AI's overall role, personality, and rules (its \"job description\") for all conversations, while a user prompt is a specific, one-off question or command for a single interaction, dictating the immediate \"what\" the AI needs to do, with system prompts acting as persistent, foundational instructions guiding the user's specific requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7e7855",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(SYSTEM_PROMPT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0866a54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (USER_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c34fb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT}\n",
    "    ],\n",
    "    reasoning_effort=\"minimal\"\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e44a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_output = response.choices[0].message.content\n",
    "json_output = json.loads(json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6d71d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac06486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "len(json_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a897034f",
   "metadata": {},
   "source": [
    "We need to get the description as part of the output to check if it has given correct results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e763ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = qdrant_client.scroll(\n",
    "    collection_name=\"Amazon-items-collection-00\",\n",
    "    scroll_filter=Filter(\n",
    "        must=[\n",
    "            FieldCondition(\n",
    "                key=\"parent_asin\",\n",
    "                match=MatchValue(value=\"B0BNVKS9WH\")\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    limit=100,\n",
    "    with_payload=True,\n",
    "    with_vectors=False\n",
    ")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49b429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "points[0].payload\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca1dfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_description(parent_asin: str) -> str:  \n",
    "    \n",
    "    points = qdrant_client.scroll(\n",
    "        collection_name=\"Amazon-items-collection-00\",\n",
    "        scroll_filter=Filter(\n",
    "            must=[\n",
    "                FieldCondition(\n",
    "                    key=\"parent_asin\",\n",
    "                    match=MatchValue(value=parent_asin)\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit=100,\n",
    "        with_payload=True,\n",
    "        with_vectors=False\n",
    "    )[0]\n",
    "\n",
    "    return points[0].payload[\"description\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdd3898",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_description(\"B0BNVKS9WH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ce35f4",
   "metadata": {},
   "source": [
    "Create Eval dataset in LangSmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b6927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(api_key=os.environ[\"LANGSMITH_API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06fca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset_name = \"rag-evaluation-dataset\"\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Dataset for evaluating RAG pipeline\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d10887",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in json_output:\n",
    "    client.create_example(\n",
    "        dataset_id=dataset.id,\n",
    "        inputs={\"question\": item[\"question\"]},\n",
    "        outputs={\n",
    "            \"ground_truth\": item[\"answer_example\"],\n",
    "            \"reference_context_ids\": item[\"chunk_ids\"],\n",
    "            \"reference_descriptions\": [get_description(id) for id in item[\"chunk_ids\"]]\n",
    "        }\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
